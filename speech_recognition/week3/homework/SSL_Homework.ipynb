{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework: Learning Audio Representations with Self-Supervision\n",
        "\n",
        "In this homework, we will consolidate the knowledge gained during the seminar and further explore methods for self-supervised learning of audio representations.\n",
        "During the seminar, we implemented and trained a model based on contrastive learning (InfoNCE). Now, we will extend this work by implementing non-contrastive learning (NCL) approaches and comparing them with previously studied methods.\n",
        "\n",
        "We will examine how different training paradigms — supervised, contrastive, and non-contrastive — affect the quality of learned embeddings and the stability of the training process\n"
      ],
      "metadata": {
        "id": "A3fAeMik2RnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Format Contrastive Learning of Audio Representations(Paper from seminar)\n",
        "\n",
        "The core idea of this approach is to learn robust audio embeddings by contrasting\n",
        "different *formats* (or views) of the same audio sample.  \n",
        "For example, one branch may encode the **raw waveform (1D)** while another encodes\n",
        "its **spectrogram (2D)**.  \n",
        "\n",
        "By applying a contrastive loss (InfoNCE), the model is trained to:\n",
        "- **Pull together** embeddings from different formats of the same audio,\n",
        "- **Push apart** embeddings from different audio samples.  \n",
        "\n",
        "This multi-format setup encourages the encoder to capture **shared semantic content**\n",
        "across input representations, leading to more general and transferable audio features.\n",
        "\n",
        "[paper1](https://arxiv.org/pdf/2103.06508), [paper2](https://arxiv.org/pdf/2010.09542)\n",
        "\n",
        "[github source](https://github.com/HondamunigePrasannaSilva/CLAR?tab=readme-ov-file)"
      ],
      "metadata": {
        "id": "ykG59yPqxMQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AudioSet\n",
        "\n",
        "Dataset with 10 numbers pronounced\n",
        "```\n",
        "!git clone https://github.com/soerenab/AudioMNIST.git\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zh89RGAjxhNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1(2 points)\n",
        "\n",
        "Impelment strightforward classifier training based on waveforms or spectrogram(use models from seminar). Train it in supervised manner and compute accuracy"
      ],
      "metadata": {
        "id": "_zcKcWbTxVu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here"
      ],
      "metadata": {
        "id": "zfO4_X4wxINt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2(2 points)\n",
        "\n",
        "Train the Multi-Format Contrastive Learning of Audio Representations model (implemented during the seminar) until convergence. Plot the loss and accuracy curves to verify that the training process has stabilized."
      ],
      "metadata": {
        "id": "59qTu8Ciyj_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here"
      ],
      "metadata": {
        "id": "t8dDpBLHyi0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3(4 points)\n",
        "\n",
        "Replace the InfoNCE loss in Multi-Format Contrastive Learning of Audio Representations with a Non-Contrastive Learning method.\n",
        "Train the model until convergence, then plot the loss and accuracy curves to check that training has stabilized.\n",
        "\n",
        "You can try one of the following NCL methods:\n",
        "- BYOL([paper](https://arxiv.org/pdf/2006.07733))\n",
        "- SimSiam([paper](https://arxiv.org/pdf/2011.10566))\n",
        "- Barlow Twins([paper](https://arxiv.org/pdf/2103.03230))\n",
        "- VicReg([paper](https://arxiv.org/pdf/2105.04906))\n",
        "\n",
        "Feel free to use a more recent Non-Contrastive approach if you prefer—just explain briefly why you chose it.\n"
      ],
      "metadata": {
        "id": "QOo6rOAdz7dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here"
      ],
      "metadata": {
        "id": "cR88lDsVz2s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4(2 points)\n",
        "\n",
        "Evaluate and compare three training setups on the validation subset:\n",
        "\n",
        "1. Supervised training\n",
        "\n",
        "2. InfoNCE (contrastive learning)\n",
        "\n",
        "3. Non-Contrastive Learning (NCL)\n",
        "\n",
        "Use either the 2D or 1D encoder—or combine their embeddings.\n",
        "Identify which setup performs best and explain why it outperforms the others."
      ],
      "metadata": {
        "id": "93Dcfwde1RtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code here"
      ],
      "metadata": {
        "id": "I_7ln6Sg1Qtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SpzZ2DDV2O0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}