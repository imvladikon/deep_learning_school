{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminar_cnn and rnn",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUI02UFXY5lZ"
      },
      "source": [
        "# ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° RNN. ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°.\n",
        "\n",
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ’ ÑÑ‚Ğ¾ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ğµ Ğ¼Ñ‹ Ğ¿Ğ¾Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼Ğ¸Ğ¼ÑÑ Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ĞµĞ¹ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°, Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ¸ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ñ Ğ´Ğ²ÑƒĞ¼Ñ Ğ¸Ğ· Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‚ Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹ â€“Â RNN Ğ¸ GRU.\n",
        "\n",
        "ĞĞ°Ğ¼ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¾Ğ´Ğ½Ğ° Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Ğ¾Ñ‚ `HuggingFaceğŸ¤—` Ğ¿Ğ¾Ğ´ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ `datasets`. ĞĞ½Ğ° ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ Ğ² NLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eSlBJXbpNhH"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwNeXLCXr4ue"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import gensim.downloader as api\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBGF3mNQKAgN"
      },
      "source": [
        "# Ğ—Ğ° Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ğ·Ğ¼!\n",
        "SEED = 0xDEAD\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.random.manual_seed(SEED)\n",
        "torch.cuda.random.manual_seed_all(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-nNNuqZ9GN"
      },
      "source": [
        "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹: `AgNews`. Ğ’ Ğ½ĞµĞ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ñ‹ Ñ‚ĞµĞºÑÑ‚Ñ‹ Ğ½Ğ° 4 Ñ‚ĞµĞ¼Ñ‹: `World`, `Sports`, `Business`, `Sci/Tech`. ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ¸ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LREB3dpscnH"
      },
      "source": [
        "dataset = datasets.load_dataset(\"ag_news\")\n",
        "dataset[\"train\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YysP5HpsiBX"
      },
      "source": [
        "dataset[\"train\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QK1tDYKaTJa"
      },
      "source": [
        "Ğ’ `dataset` Ğ½Ğ°Ñ…Ğ¾Ğ´ÑÑ‚ÑÑ `train` Ğ¸ `test` Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjEB-Yv09AQo"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmSIXBJPaegW"
      },
      "source": [
        "Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ñ€ĞµĞ²Ñ€Ğ°Ñ‰Ğ°Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° ÑĞ»Ğ¾Ğ² Ğ² Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¼Ñ‹ Ğ±ÑƒĞ´ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸. ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° Ğ¸Ñ… ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸ Ğ²Ñ‹Ğ±ĞµÑ€ĞµĞ¼ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸Ğ· Ğ½Ğ¸Ñ…."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGW4jSiswVDy"
      },
      "source": [
        "print(\"\\n\".join(api.info()['models'].keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd1RzPKhwC3q"
      },
      "source": [
        "word2vec = api.load(\"glove-twitter-50\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAIznT0Kaue8"
      },
      "source": [
        "Ğ¢Ğ¾ĞºĞµĞ½ĞµĞ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ñˆ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ NLTK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6k91UgcAQNz"
      },
      "source": [
        "MAX_LENGTH=128\n",
        "\n",
        "tokenizer = nltk.WordPunctTokenizer()\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda item: {\n",
        "        \"tokenized\": tokenizer.tokenize(item[\"text\"])[:MAX_LENGTH]\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqrtz1bDk2Ws"
      },
      "source": [
        "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ´Ğ¸Ğ¼ Ğ¼Ğ°Ğ¿Ğ¸Ğ½Ğ³ Ğ¸Ğ· Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ² Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMDWoNeEArA6"
      },
      "source": [
        "word2idx = {word: idx for idx, word in enumerate(word2vec.index2word)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G_q_EgHlCWC"
      },
      "source": [
        "ĞŸĞµÑ€ĞµĞ²ĞµĞ´ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ² Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVQX-b8mEKtA"
      },
      "source": [
        "def encode(word):\n",
        "    if word in word2idx.keys():\n",
        "        return word2idx[word]\n",
        "    return word2idx[\"unk\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9byefh6DSjV"
      },
      "source": [
        "dataset = dataset.map(\n",
        "    lambda item: {\n",
        "        \"features\": [encode(word) for word in item[\"tokenized\"]]\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y05UCYA4D0OC"
      },
      "source": [
        "dataset[\"train\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiHvDSTAHJ8D"
      },
      "source": [
        "dataset.remove_columns_([\"text\", \"tokenized\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOI1-AlYlbgA"
      },
      "source": [
        "ĞŸĞµÑ€ĞµĞ²ĞµĞ´ĞµĞ¼ Ğ² Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ñ‹"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VZ9EBnCK9V3"
      },
      "source": [
        "dataset.set_format(type='torch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWdVJKsnPtYX"
      },
      "source": [
        "dataset[\"train\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6haisMrlmSu"
      },
      "source": [
        "Ğ¥Ğ¾Ñ‚Ğ¸Ğ¼ ÑĞºĞ»ĞµĞ¸Ñ‚ÑŒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğ¸. Ğ”Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞµĞ¼ `collate_fn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzwuahwBxb2l"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    max_len = max(len(row[\"features\"]) for row in batch)\n",
        "    input_embeds = torch.empty((len(batch), max_len), dtype=torch.long)\n",
        "    labels = torch.empty(len(batch), dtype=torch.long)\n",
        "    for idx, row in enumerate(batch):\n",
        "        to_pad = max_len - len(row[\"features\"])\n",
        "        input_embeds[idx] = torch.cat((row[\"features\"], torch.zeros(to_pad)))\n",
        "        labels[idx] = row[\"label\"]\n",
        "    return {\"features\": input_embeds, \"labels\": labels}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdVbtWJzszbu"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "    k: DataLoader(\n",
        "        ds, shuffle=(k==\"train\"), batch_size=32, collate_fn=collate_fn\n",
        "    ) for k, ds in dataset.items()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsqpZ-WfPqe"
      },
      "source": [
        "## CNN\n",
        "\n",
        "ĞŸĞµÑ€Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ Ğ¼Ñ‹ Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼: CNN. ĞĞ´Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ğ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ĞµĞ¹ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸. Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ Ğ½Ğ°Ğ´Ğ¾ ÑĞ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ `AdaptiveMaxPool1d` Ğ¸Ğ»Ğ¸ `AdiptiveAvgPool1d`. Ğ”Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ»ÑĞ±ÑƒÑ Feed Forward Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9DMopWCiBlD"
      },
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(len(word2idx), embedding_dim=embed_size)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        self.cl = nn.Sequential(\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)  # (batch_size, seq_len, embed_dim)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.cnn(x)\n",
        "        prediction = self.cl(x)\n",
        "        return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ed-3nQHjDrd"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CNNModel(word2vec.vector_size, 50).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oZjYEBkgauj"
      },
      "source": [
        "ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Smd5_03CSp"
      },
      "source": [
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "\n",
        "def training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2):\n",
        "    for e in trange(num_epochs, leave=False):\n",
        "        model.train()\n",
        "        num_iter = 0\n",
        "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
        "        for batch in pbar:\n",
        "            optimizer.zero_grad()\n",
        "            input_embeds = batch[\"features\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            prediction = model(input_embeds)\n",
        "            loss = criterion(prediction, labels)\n",
        "            loss.backward()\n",
        "            if max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "            num_iter += 1\n",
        "        valid_loss = 0\n",
        "        valid_acc = 0\n",
        "        num_iter = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            num_objs = 0\n",
        "            for batch in loaders[\"test\"]:\n",
        "                input_embeds = batch[\"features\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "                prediction = model(input_embeds)\n",
        "                valid_loss += criterion(prediction, labels)\n",
        "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
        "                num_objs += len(labels)\n",
        "                num_iter += 1\n",
        "\n",
        "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOi77V2XjDpg"
      },
      "source": [
        "training(model, criterion, optimizer, num_epochs, loaders)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN8E8-ZSgnul"
      },
      "source": [
        "## RNN\n",
        "\n",
        "Ğ’Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: RNN. Ğ­Ñ‚Ğ¾ Ñ€ĞµĞºÑƒÑ€Ñ€ĞµĞ½Ñ‚Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ, Ğ¾Ğ½Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¸Ğ· Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğ¹ Ğ¸Ñ‚Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾. Ğ­Ñ‚Ğ¾ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»:\n",
        "\n",
        "$$\n",
        "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
        "$$\n",
        "\n",
        "ĞĞ°Ğ¿Ğ¸ÑˆĞµĞ¼ ÑÑ‚Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ Ğ½Ğ° `Torch`!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBKQXeMOwie-"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.w_h = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
        "        self.b_h = nn.Parameter(torch.rand((1, hidden_size)))\n",
        "        self.w_x = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
        "        self.b_x = nn.Parameter(torch.rand(1, hidden_size))\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        '''\n",
        "        x â€“ torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
        "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
        "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
        "        '''\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
        "        seq_length = x.size(1)\n",
        "        for cur_idx in range(seq_length):\n",
        "            hidden = torch.tanh(\n",
        "                x[:, cur_idx] @ self.w_x + self.b_x + hidden @ self.w_h + self.b_h\n",
        "            )\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LJ3ZIuZzamP"
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
        "        self.rnn = RNN(embed_size, hidden_size)\n",
        "        self.cls = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        hidden = self.rnn(x)\n",
        "        output = self.cls(hidden)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftuDhqdtzaj-"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = RNNModel(word2vec.vector_size, 50).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 1\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx62ofTU3CNY"
      },
      "source": [
        "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJqh9eWIhxE0"
      },
      "source": [
        "## GRU\n",
        "\n",
        "Ğ¢Ñ€ĞµÑ‚ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: GRU. ĞĞ½Ğ° ÑƒÑĞ»Ğ¾Ğ¶Ğ½ĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ `RNN`. Ğ“Ğ»Ğ°Ğ½Ğ°Ñ Ğ¸Ğ´ĞµÑ GRU: Ğ³ĞµĞ¹Ñ‚Ñ‹. Ğ¢Ğ°Ğº Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ÑÑ \"Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ\" Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ â€“ Ğ¾Ğ½Ğ° Ğ¼Ğ°ÑĞºĞ¸Ñ€ÑƒĞµÑ‚ Ñ‡Ğ°ÑÑ‚ÑŒ ÑÑ‚Ğ°Ñ€Ğ¾Ğ³Ğ¾ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğ³Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ, ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ Ğ½Ğ° ÑÑ‚Ğ¾Ğ¼ Ğ¼ĞµÑÑ‚Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğµ. ĞœĞ¾Ğ´ĞµĞ»ÑŒ GRU Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ÑÑ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼:\n",
        "\n",
        "$$\n",
        "\\begin{array}{ll}\n",
        "            r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
        "            z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
        "            n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
        "            h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
        "        \\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi1yv2cy3CJB"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.w_rh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
        "        self.b_rh = nn.Parameter(torch.rand((1, hidden_size)))\n",
        "        self.w_rx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
        "        self.b_rx = nn.Parameter(torch.rand(1, hidden_size))\n",
        "\n",
        "        self.w_zh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
        "        self.b_zh = nn.Parameter(torch.rand((1, hidden_size)))\n",
        "        self.w_zx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
        "        self.b_zx = nn.Parameter(torch.rand(1, hidden_size))\n",
        "\n",
        "        self.w_nh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
        "        self.b_nh = nn.Parameter(torch.rand((1, hidden_size)))\n",
        "        self.w_nx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
        "        self.b_nx = nn.Parameter(torch.rand(1, hidden_size))\n",
        "\n",
        "    def forward(self, x, hidden = None):\n",
        "        '''\n",
        "        x â€“ torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
        "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
        "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
        "        '''\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
        "        \n",
        "        for cur_idx in range(x.size(1)):\n",
        "            r = torch.sigmoid(\n",
        "                x[:, cur_idx] @ self.w_rx + self.b_rx + hidden @ self.w_rh + self.b_rh\n",
        "            )\n",
        "            z = torch.sigmoid(\n",
        "                x[:, cur_idx] @ self.w_zx + self.b_zx + hidden @ self.w_zh + self.b_zh\n",
        "            )\n",
        "            n = torch.tanh(\n",
        "                x[:, cur_idx] @ self.w_nx + self.b_nx + r * (hidden @ self.w_nh + self.b_nh)\n",
        "            )\n",
        "            hidden = (1 - z) * n + z * hidden\n",
        "\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bisyVic-3CDu"
      },
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(len(word2idx), embed_size)\n",
        "        self.gru = GRU(embed_size, hidden_size)\n",
        "        self.cls = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        hidden = self.gru(x)\n",
        "        output = self.cls(hidden)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UASjrUtDzaf3"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 1\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlom9sHdzac6"
      },
      "source": [
        "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG4My7G5i5Vs"
      },
      "source": [
        "## GRU + Embeddings\n",
        "\n",
        "ĞœÑ‹ Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ‚Ğ°Ğº Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ğ»Ğ¸ ÑĞ¼Ğ±ÑĞ´Ğ¸Ğ½Ğ³Ğ¸ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ. Ğ”Ğ°Ğ²Ğ°Ğ¹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ñ… Ğ²Ğ¼ĞµÑÑ‚Ğ¾ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸! Ğ”Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ´Ğ¾ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµĞ´ĞµĞ»Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¿Ğ¾Ğ´Ğ°Ñ‡Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ `Embedding`. ĞŸĞ¾-ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ `GRU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbYLzLdYLxjc"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 1\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-TxEwzMLsuz"
      },
      "source": [
        "with torch.no_grad():\n",
        "    for word, idx in word2idx.items():\n",
        "        if word in word2vec:\n",
        "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opw85y82Mhvf"
      },
      "source": [
        "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T91mZsx_b8z8"
      },
      "source": [
        "ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ·Ğ°Ğ¼Ğ¾Ñ€Ğ¾Ğ·Ğ¸Ñ‚ÑŒ ÑĞ¼Ğ±ĞµĞ´Ğ¸Ğ½Ğ³Ğ¸ Ğ½Ğ° Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸ÑÑ… Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ. Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğµ ÑĞ¸Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ°ÑˆĞ¸ ÑĞ¼Ğ±ĞµĞ´Ğ¸Ğ½Ğ³Ğ¸ Ğ½Ğ° Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸ÑÑ…."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trrbDTJqMvLK"
      },
      "source": [
        "def freeze_embeddings(model, req_grad=False):\n",
        "    embeddings = model.embed\n",
        "    for c_p in embeddings.parameters():\n",
        "        c_p.requires_grad = req_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcPZxlseJME5"
      },
      "source": [
        "def training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2, num_freeze_iter=1000):\n",
        "    freeze_embeddings(model)\n",
        "    for e in trange(num_epochs, leave=False):\n",
        "        model.train()\n",
        "        num_iter = 0\n",
        "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
        "        for batch in pbar:\n",
        "            if num_iter > num_freeze_iter and e < 1:\n",
        "                freeze_embeddings(model, True)\n",
        "            optimizer.zero_grad()\n",
        "            input_embeds = batch[\"features\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            prediction = model(input_embeds)\n",
        "            loss = criterion(prediction, labels)\n",
        "            loss.backward()\n",
        "            if max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "            num_iter += 1\n",
        "        valid_loss = 0\n",
        "        valid_acc = 0\n",
        "        num_iter = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            num_objs = 0\n",
        "            for batch in loaders[\"test\"]:\n",
        "                input_embeds = batch[\"features\"].to(device)\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "                prediction = model(input_embeds)\n",
        "                valid_loss += criterion(prediction, labels)\n",
        "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
        "                num_objs += len(labels)\n",
        "                num_iter += 1\n",
        "\n",
        "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYbcqM2iKERh"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "num_epochs = 1\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3i8-_MhKHCo"
      },
      "source": [
        "with torch.no_grad():\n",
        "    for word, idx in word2idx.items():\n",
        "        if word in word2vec:\n",
        "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKIdxoobKLas"
      },
      "source": [
        "training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JDRH3TkK6VS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}